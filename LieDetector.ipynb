{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "LQoLNr5iEvq2",
   "metadata": {
    "id": "LQoLNr5iEvq2"
   },
   "source": [
    "# Lie Detector\n",
    "## General Description\n",
    "#### In this Project, we are using Data contains Sentences as the first column and the last column contain the information of whether this sentence is a lie or not. Lie being 1 and Not Lie being 0. We are trying to find the P( Lie | Query )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rOtgUTGyQcUk",
   "metadata": {
    "id": "rOtgUTGyQcUk"
   },
   "source": [
    "\n",
    "## We are using Navie Bayesian Network\n",
    "\n",
    "                          Lie (Class)\n",
    "                        /   |    |   \\\n",
    "                      W₁   W₂   W₃  ... Wₙ (Words)\n",
    "\n",
    "Lie (root node): Binary class (True = lie, False = truth).\n",
    "\n",
    "Words (child nodes): Each word W<sub>i</sub> depends only on the class Lie\n",
    "\n",
    "Edges: All the edges are pointing from Lie to W<sub>i</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7102b2b-07a3-4b0c-a7cc-d08800f4312c",
   "metadata": {
    "id": "e7102b2b-07a3-4b0c-a7cc-d08800f4312c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z228B9Y1Kzam",
   "metadata": {
    "id": "z228B9Y1Kzam"
   },
   "source": [
    "# Cleaning Data\n",
    "- Drop all columns not contain the sentence and whether it is a lie.\n",
    "- Store them in tuple as (list of words , whether it is a lie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c60f596-1be3-40f2-9f92-807dd66992ca",
   "metadata": {
    "id": "2c60f596-1be3-40f2-9f92-807dd66992ca"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('politifact_clean_binarized.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d78095ea-70d0-49fa-b4b7-966d6cb7843b",
   "metadata": {
    "id": "d78095ea-70d0-49fa-b4b7-966d6cb7843b"
   },
   "outputs": [],
   "source": [
    "# Training set\n",
    "training_data = []\n",
    "for i in range(0,11188-100): # We are only training on the first 11087 data, the last 100 will be the validation set\n",
    "  word_list = data[['statement','veracity']].iloc[i].tolist()[0]\n",
    "  words = re.sub(r'[^\\w\\s]', '', word_list).split()\n",
    "  if data[['statement','veracity']].iloc[i].tolist()[1] == 0:\n",
    "    lie_tupple = (words,True)\n",
    "  else:\n",
    "    lie_tupple = (words,False)\n",
    "  training_data.append(lie_tupple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "E2SpZNRDaJ6F",
   "metadata": {
    "id": "E2SpZNRDaJ6F"
   },
   "outputs": [],
   "source": [
    "# Validation set\n",
    "validation_data = []\n",
    "for i in range(11087,11188):\n",
    "  word_list = data[['statement','veracity']].iloc[i].tolist()[0]\n",
    "  words = re.sub(r'[^\\w\\s]', '', word_list).split()\n",
    "  if data[['statement','veracity']].iloc[i].tolist()[1] == 0:\n",
    "    lie_tupple = (words,True)\n",
    "  else:\n",
    "    lie_tupple = (words,False)\n",
    "  validation_data.append(lie_tupple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6YED4LMXQ5hR",
   "metadata": {
    "id": "6YED4LMXQ5hR"
   },
   "source": [
    "## Current Approach: Words are treated as a bag-of-words (order-agnostic).\n",
    "\n",
    "### Reason:\n",
    "\n",
    "- Naive Bayes assumes conditional independence between words given the class. Ordering adds complexity and violates this assumption.\n",
    "\n",
    "- Simplifies computation and reduces dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3naEw8NdJcsP",
   "metadata": {
    "id": "3naEw8NdJcsP"
   },
   "source": [
    "# Step-by-Step Math Calculation\n",
    "\n",
    "## 1. Priors: \\( P( Lie ) \\) and \\( P( Not Lie ) \\)\n",
    "\n",
    "- Calculate class probabilities from training data:\n",
    "\n",
    "  P(Lie) = Number of lies/Total statements\n",
    "  \n",
    "  P(Not Lie) = 1 - P(Lie)\n",
    "\n",
    "## 2. Likelihoods: \\( P( W<sub>i</sub> | Lie ) \\) and \\( P( W<sub>i</sub> | Not Lie ) \\)\n",
    "\n",
    "For each word \\( W<sub>i</sub> \\) in the input query:\n",
    "\n",
    "- **Lie Class**:\n",
    "\n",
    "  P( W<sub>i</sub> | Lie ) = Count of lies containing W<sub>i</sub> / Total lies\n",
    "\n",
    "- **Not Lie Class**:\n",
    "\n",
    "  P( W<sub>i</sub> | Not Lie ) = Count of truths containing W<sub>i</sub> / Total truths\n",
    "\n",
    "\n",
    "## 3. Joint Probability of Query Given Class\n",
    "\n",
    "- Assume independence between words:\n",
    "\n",
    "  P( Query | Lie ) = Product of all W<sub>i</sub> over P( W<sub>i</sub> | Lie )\n",
    "\n",
    "  P( Query | Not Lie ) = Product of all W<sub>i</sub> over P( W<sub>i</sub> | Not Lie )\n",
    "\n",
    "\n",
    "## 4. Posterior Probability (Bayes’ Theorem)\n",
    "\n",
    "P ( Query ) =  P( Query | Lie ) * P( Lie ) + P( Query | Not Lie ) * P( Not Lie )\n",
    "\n",
    "P(Lie|Query) = P( Query | Lie ) * P( Lie ) / P ( Query )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T488gh_JTAv8",
   "metadata": {
    "id": "T488gh_JTAv8"
   },
   "source": [
    "## Exmaple:\n",
    "# Example Calculation\n",
    "\n",
    "From the code’s test case:  \n",
    "**Query:** `[\"absolutely\", \"my\"]`  \n",
    "\n",
    "Assume training data has:  \n",
    "\n",
    "- Total lies (`numLie`) = 5,000  \n",
    "- Total truths (`numNotLie`) = 6,188  \n",
    "- **absolutely** appears in 3,000 lies and 1,000 truths  \n",
    "- **my** appears in 2,500 lies and 4,000 truths  \n",
    "\n",
    "## Step 1: Priors  \n",
    "\n",
    "P(Lie) = 5000 / 11188 = 0.447\n",
    "\n",
    "P(Not Lie) = 1 - 0.447 = 0.553\n",
    "\n",
    "## Step 2: Likelihoods  \n",
    "\n",
    "P( absolutely | Lie ) = 3000 / 5000 = 0.6\n",
    "\n",
    "P( absolutely | Not Lie) = 1000/6188 = 0.162\n",
    "\n",
    "P( my | Lie) = 2500 / 5000 = 0.5\n",
    "\n",
    "P( my | Not Lie) = 4000 / 6188 = 0.646\n",
    "\n",
    "\n",
    "## Step 3: Joint Probabilities  \n",
    "\n",
    "P(Query | Lie) = 0.6 * 0.5 = 0.3\n",
    "\n",
    "P(Query | Not Lie) = 0.162 * 0.646 = 0.105\n",
    "\n",
    "\n",
    "## Step 4: Posterior  \n",
    "\n",
    "P(Lie | Query) = 0.3 * 0.447 / (0.3* 0.447 + 0.105 * 0.553) = 0.698\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33518b4e-4b88-4c69-bee7-43e701386f20",
   "metadata": {
    "id": "33518b4e-4b88-4c69-bee7-43e701386f20"
   },
   "outputs": [],
   "source": [
    "def calculate_lie_probability(training_data, query):\n",
    "    \"\"\"\n",
    "    Calculate the probability of an input statement being spam.\n",
    "\n",
    "    Args:\n",
    "        training_data (list of tuples): Each tuple contains a list of words and a boolean indicating\n",
    "                                        if the list is lie (True) or not lie (False).\n",
    "        query (list of str): Words in the input statement to evaluate.\n",
    "\n",
    "    Returns:\n",
    "        float: Probability that the input statement is lie.\n",
    "    \"\"\"\n",
    "    P_lie_given_query = 1.0\n",
    "\n",
    "    # checks for at lest one valid word exist in the input statement\n",
    "    # and keep only the valid words\n",
    "    valid = False\n",
    "    valid_query = []\n",
    "    for i in query:\n",
    "        for words, isLie in training_data:\n",
    "            if i in words:\n",
    "                valid = True\n",
    "                valid_query.append(i)\n",
    "                break\n",
    "    if not valid:\n",
    "        return -1\n",
    "    query = valid_query\n",
    "\n",
    "    # calculate P(Wi|Lie) for all words within W*, along with P(Lie)\n",
    "    PLie = 0\n",
    "    numLie = 0\n",
    "    P_Wi_given_lie_list = []\n",
    "    P_Wi_given_not_lie_list = []\n",
    "    for i in query:\n",
    "        numLie = 0\n",
    "        numWgivenLie = 0\n",
    "        numNotLie = 0\n",
    "        numWgivenNotLie = 0\n",
    "        for words, isLie in training_data:\n",
    "            if isLie:\n",
    "                numLie += 1\n",
    "                if i in words:\n",
    "                    numWgivenLie += 1\n",
    "            else:\n",
    "                numNotLie += 1\n",
    "                if i in words:\n",
    "                    numWgivenNotLie += 1\n",
    "        PLie = numLie / len(training_data)\n",
    "        PNotLie = 1 - PLie\n",
    "        # Store P(Wi|Lie)\n",
    "        P_Wi_given_lie_list.append(numWgivenLie/numLie)\n",
    "        # Store P(Wi|notLie)\n",
    "        P_Wi_given_not_lie_list.append(numWgivenNotLie/numNotLie)\n",
    "\n",
    "    PLie = numLie / len(training_data)\n",
    "    PNotLie = 1 - PLie\n",
    "\n",
    "    # Calculate P(W*|Lie)\n",
    "    P_W_given_Lie = 1\n",
    "    for i in P_Wi_given_lie_list:\n",
    "        P_W_given_Lie *= i\n",
    "\n",
    "    # Calculate P(W*|notLie)\n",
    "    P_W_given_not_Lie = 1\n",
    "    for i in P_Wi_given_not_lie_list:\n",
    "        P_W_given_not_Lie *= i\n",
    "\n",
    "    if P_W_given_Lie == 0 and P_W_given_not_Lie == 0:\n",
    "      return -1\n",
    "\n",
    "    # Calculate P_lie_given_query\n",
    "    P_lie_given_query = P_W_given_Lie * PLie / (P_W_given_Lie * PLie + P_W_given_not_Lie * PNotLie)\n",
    "\n",
    "    return P_lie_given_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hFenaxGeOqSJ",
   "metadata": {
    "id": "hFenaxGeOqSJ"
   },
   "source": [
    "##Handle Unknown word\n",
    "  Words not present in the training data are removed from the query. If all words are invalid, the model returns -1 (unknown)\n",
    "#### Motivation:\n",
    "\n",
    "- Simplifies the problem by ignoring words that the model hasn’t learned to associate with lies/truths.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vrOJU4a8RQqu",
   "metadata": {
    "id": "vrOJU4a8RQqu"
   },
   "source": [
    "##OOV Problem & Short Statements\n",
    "###Current Handling:\n",
    "\n",
    "- Delete OOV words. For short statements, this risks leaving only common propositional words (e.g., “the”, “is”), which are uninformative.\n",
    "\n",
    "- Example: Query [\"wn\", \"m\"] returns -100% due to no valid words.\n",
    "\n",
    "### There might have Better Approaches:\n",
    "\n",
    "- Minimum Word Threshold: Require a minimum number of valid words to make predictions.\n",
    "\n",
    "- New Token: Set a new token <UNK>, which represents all the words that are invalid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FLRcf1NoSCax",
   "metadata": {
    "id": "FLRcf1NoSCax"
   },
   "source": [
    "## Rare Words & Generalization\n",
    "### Problem:\n",
    "\n",
    "Words appearing very few times in training data (e.g., 1–2 occurrences) lead to noisy estimates of\n",
    "P( W<sub>i</sub> ∣ Class )\n",
    "\n",
    "\n",
    "- Example: If “absolutely” appears once in lies and never in truths,\n",
    "P( absolutely ∣ Lie )=1, which is unreliable.\n",
    "\n",
    "### Possible Solution\n",
    "- Word Embeddings:\n",
    "\n",
    "  Replace bag-of-words with embeddings (e.g., Word2Vec) to capture semantic similarity.\n",
    "\n",
    "  Advantage: Generalizes to synonyms (e.g., “money” ↔ “cash”).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b07c16d0-ce99-4bea-93ad-4311a9cb1f1e",
   "metadata": {
    "id": "b07c16d0-ce99-4bea-93ad-4311a9cb1f1e"
   },
   "outputs": [],
   "source": [
    "def determine_lie(training_data,query):\n",
    "    result = calculate_lie_probability(training_data, query)\n",
    "    if result >= 0.5:\n",
    "        print (\"Lie!\")\n",
    "    elif result >= 0 and result < 0.5:\n",
    "        print (\"Truth\")\n",
    "    else:\n",
    "        print (\"Hmm, I have never seen anything like this before. I may need to upgrade my training data in the future. For now, try another sentence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fG1QdaqY3GI",
   "metadata": {
    "id": "7fG1QdaqY3GI"
   },
   "outputs": [],
   "source": [
    "def userInput():\n",
    "    uInput = input(\"Please enter a sentence: \")\n",
    "    arr = uInput.split()\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oXuovjDGXcx4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "oXuovjDGXcx4",
    "outputId": "1f5dedf3-c3a8-4d55-a897-564aba5001ae"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter a sentence:  I am Donald Trump\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lie!\n"
     ]
    }
   ],
   "source": [
    "#Test user input function\n",
    "#I will absolutely sign this contract for money\n",
    "query = userInput()\n",
    "while( not query == [\"stop\"]):\n",
    "    result = determine_lie(training_data, query)\n",
    "    query = userInput()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0010db-d2a0-4217-8bca-bdcfaf95e895",
   "metadata": {
    "id": "0a0010db-d2a0-4217-8bca-bdcfaf95e895"
   },
   "source": [
    "#### the cells below is only for testing the determine_lie function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0deJn4xQarMJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0deJn4xQarMJ",
    "outputId": "6ef1c512-c748-4f10-9a32-e32a33fde5d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy obtained from the validation set is 58.43% .\n"
     ]
    }
   ],
   "source": [
    "#  Test with validation set\n",
    "total_count = len(validation_data)\n",
    "correct_count = 0\n",
    "for sentence, veracity in validation_data:\n",
    "  prob = calculate_lie_probability(training_data, sentence)\n",
    "  if prob >= 0.5:\n",
    "    if veracity:\n",
    "      correct_count += 1\n",
    "  elif prob >= 0 and prob < 0.5:\n",
    "    if not veracity:\n",
    "      correct_count += 1\n",
    "  else:\n",
    "    total_count -= 1\n",
    "accuracy = correct_count / total_count\n",
    "print(f\"The accuracy obtained from the validation set is {accuracy * 100:.2f}% .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fdc0d24-303d-4e54-85cf-04847aa93ac9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7fdc0d24-303d-4e54-85cf-04847aa93ac9",
    "outputId": "aca318dd-32c5-45a0-d26e-39084c703fb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This sentence is -100.00% likely to be a lie.\n",
      "Hmm, I have never seen anything like this before. I may need to upgrade my training data in the future. For now, try another sentence.\n",
      "This sentence is 59.86% likely to be a lie.\n",
      "Lie!\n",
      "This sentence is 68.17% likely to be a lie.\n",
      "Lie!\n",
      "This sentence is 61.46% likely to be a lie.\n",
      "Lie!\n",
      "This sentence is 61.46% likely to be a lie.\n",
      "Lie!\n",
      "This sentence is 60.00% likely to be a lie.\n",
      "Lie!\n",
      "This sentence is 60.87% likely to be a lie.\n",
      "Lie!\n",
      "This sentence is 74.68% likely to be a lie.\n",
      "Lie!\n"
     ]
    }
   ],
   "source": [
    "#  Testing with or without own dataset\n",
    "#  training_data = [(['must', 'absolutely'], True),\n",
    "#  (['must', 'work', 'promise', 'absolutely'], False),\n",
    "#  (['money', 'contract'], True),\n",
    "#  (['money', 'work'], False),\n",
    "#  (['must'], True),\n",
    "#  (['must', 'money', 'contract'], True),\n",
    "#  (['must', 'money', 'contract', 'work'], True),\n",
    "#  (['project', 'absolutely'], False),\n",
    "#  (['work', 'absolutely'], False),\n",
    "#  (['work', 'promise'], False)]\n",
    "\n",
    "query = [\"wn\", \"m\"]\n",
    "prob = calculate_lie_probability(training_data, query)\n",
    "print(f\"This sentence is {prob * 100:.2f}% likely to be a lie.\")\n",
    "result = determine_lie(training_data, query)\n",
    "\n",
    "query = [\"absolutely\", \"my\"]\n",
    "prob = calculate_lie_probability(training_data, query)\n",
    "print(f\"This sentence is {prob * 100:.2f}% likely to be a lie.\")\n",
    "result = determine_lie(training_data, query)\n",
    "\n",
    "query = ['absolutely', 'work']\n",
    "prob = calculate_lie_probability(training_data, query)\n",
    "print(f\"This sentence is {prob * 100:.2f}% likely to be a lie.\")\n",
    "result = determine_lie(training_data, query)\n",
    "\n",
    "query = ['must', 'money']\n",
    "prob = calculate_lie_probability(training_data, query)\n",
    "print(f\"This sentence is {prob * 100:.2f}% likely to be a lie.\")\n",
    "result = determine_lie(training_data, query)\n",
    "\n",
    "query = ['money', 'must']\n",
    "prob = calculate_lie_probability(training_data, query)\n",
    "print(f\"This sentence is {prob * 100:.2f}% likely to be a lie.\")\n",
    "result = determine_lie(training_data, query)\n",
    "\n",
    "query = [\"absolutely\"]\n",
    "prob = calculate_lie_probability(training_data, query)\n",
    "print(f\"This sentence is {prob * 100:.2f}% likely to be a lie.\")\n",
    "result = determine_lie(training_data, query)\n",
    "\n",
    "query = [\"contract\", \"money\", \"absolutely\"]\n",
    "prob = calculate_lie_probability(training_data, query)\n",
    "print(f\"This sentence is {prob * 100:.2f}% likely to be a lie.\")\n",
    "result = determine_lie(training_data, query)\n",
    "\n",
    "query = [\"I\", \"will\", \"absolutely\",\"sign\", \"this\", \"contract\",\"for\", \"money\"]\n",
    "prob = calculate_lie_probability(training_data, query)\n",
    "print(f\"This sentence is {prob * 100:.2f}% likely to be a lie.\")\n",
    "result = determine_lie(training_data, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lx9-HYOeXFo1",
   "metadata": {
    "id": "lx9-HYOeXFo1"
   },
   "source": [
    "##Benchmarking & Performance Analysis\n",
    "\n",
    "By validation set, the accuracy is 58.43%\n",
    "\n",
    "###Compare against baselines:\n",
    "\n",
    "- Random Guessing: Accuracy ≈ 50% (balanced data).\n",
    "\n",
    "- Always Predict Lie: Accuracy = % of lies in test data.\n",
    "\n",
    "###Model does a little bit better than baseline Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CJyC21tbijeP",
   "metadata": {
    "id": "CJyC21tbijeP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
