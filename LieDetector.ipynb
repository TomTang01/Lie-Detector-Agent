{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lie Detector\n",
        "## General Description\n",
        "#### In this Project, we are using Data contains Sentences as the first column and the last column contain the information of whether this sentence is a lie or not. Lie being 1 and Not Lie being 0. We are trying to find the P( Lie | Query )\n",
        "\n"
      ],
      "metadata": {
        "id": "LQoLNr5iEvq2"
      },
      "id": "LQoLNr5iEvq2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## We are using Navie Bayesian Network\n",
        "\n",
        "                          Lie (Class)\n",
        "                        /   |    |   \\\n",
        "                      W₁   W₂   W₃  ... Wₙ (Words)\n",
        "\n",
        "Lie (root node): Binary class (True = lie, False = truth).\n",
        "\n",
        "Words (child nodes): Each word W<sub>i</sub> depends only on the class Lie\n",
        "\n",
        "Edges: All the edges are pointing from Lie to W<sub>i</sub>"
      ],
      "metadata": {
        "id": "rOtgUTGyQcUk"
      },
      "id": "rOtgUTGyQcUk"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e7102b2b-07a3-4b0c-a7cc-d08800f4312c",
      "metadata": {
        "id": "e7102b2b-07a3-4b0c-a7cc-d08800f4312c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cleaning Data\n",
        "- Drop all columns not contain the sentence and whether it is a lie.\n",
        "- Store them in tuple as (list of words , whether it is a lie)"
      ],
      "metadata": {
        "id": "z228B9Y1Kzam"
      },
      "id": "z228B9Y1Kzam"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "2c60f596-1be3-40f2-9f92-807dd66992ca",
      "metadata": {
        "id": "2c60f596-1be3-40f2-9f92-807dd66992ca"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('politifact_clean_binarized.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "d78095ea-70d0-49fa-b4b7-966d6cb7843b",
      "metadata": {
        "id": "d78095ea-70d0-49fa-b4b7-966d6cb7843b"
      },
      "outputs": [],
      "source": [
        "# Training set\n",
        "training_data = []\n",
        "for i in range(0,11188-100): # We are only training on the first 11087 data, the last 100 will be the validation set\n",
        "  word_list = data[['statement','veracity']].iloc[i].tolist()[0]\n",
        "  words = re.sub(r'[^\\w\\s]', '', word_list).split()\n",
        "  if data[['statement','veracity']].iloc[i].tolist()[1] == 0:\n",
        "    lie_tupple = (words,True)\n",
        "  else:\n",
        "    lie_tupple = (words,False)\n",
        "  training_data.append(lie_tupple)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation set\n",
        "validation_data = []\n",
        "for i in range(11087,11188):\n",
        "  word_list = data[['statement','veracity']].iloc[i].tolist()[0]\n",
        "  words = re.sub(r'[^\\w\\s]', '', word_list).split()\n",
        "  if data[['statement','veracity']].iloc[i].tolist()[1] == 0:\n",
        "    lie_tupple = (words,True)\n",
        "  else:\n",
        "    lie_tupple = (words,False)\n",
        "  validation_data.append(lie_tupple)"
      ],
      "metadata": {
        "id": "E2SpZNRDaJ6F"
      },
      "id": "E2SpZNRDaJ6F",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Current Approach: Words are treated as a bag-of-words (order-agnostic).\n",
        "\n",
        "### Reason:\n",
        "\n",
        "- Naive Bayes assumes conditional independence between words given the class. Ordering adds complexity and violates this assumption.\n",
        "\n",
        "- Simplifies computation and reduces dimensionality."
      ],
      "metadata": {
        "id": "6YED4LMXQ5hR"
      },
      "id": "6YED4LMXQ5hR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step-by-Step Math Calculation\n",
        "\n",
        "## 1. Priors: \\( P( Lie ) \\) and \\( P( Not Lie ) \\)\n",
        "\n",
        "- Calculate class probabilities from training data:\n",
        "\n",
        "  P(Lie) = Number of lies/Total statements\n",
        "  \n",
        "  P(Not Lie) = 1 - P(Lie)\n",
        "\n",
        "## 2. Likelihoods: \\( P( W<sub>i</sub> | Lie ) \\) and \\( P( W<sub>i</sub> | Not Lie ) \\)\n",
        "\n",
        "For each word \\( W<sub>i</sub> \\) in the input query:\n",
        "\n",
        "- **Lie Class**:\n",
        "\n",
        "  P( W<sub>i</sub> | Lie ) = Count of lies containing W<sub>i</sub> / Total lies\n",
        "\n",
        "- **Not Lie Class**:\n",
        "\n",
        "  P( W<sub>i</sub> | Not Lie ) = Count of truths containing W<sub>i</sub> / Total truths\n",
        "\n",
        "\n",
        "## 3. Joint Probability of Query Given Class\n",
        "\n",
        "- Assume independence between words:\n",
        "\n",
        "  P( Query | Lie ) = Product of all W<sub>i</sub> over P( W<sub>i</sub> | Lie )\n",
        "\n",
        "  P( Query | Not Lie ) = Product of all W<sub>i</sub> over P( W<sub>i</sub> | Not Lie )\n",
        "\n",
        "\n",
        "## 4. Posterior Probability (Bayes’ Theorem)\n",
        "\n",
        "P ( Query ) =  P( Query | Lie ) * P( Lie ) + P( Query | Not Lie ) * P( Not Lie )\n",
        "\n",
        "P(Lie|Query) = P( Query | Lie ) * P( Lie ) / P ( Query )"
      ],
      "metadata": {
        "id": "3naEw8NdJcsP"
      },
      "id": "3naEw8NdJcsP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exmaple:\n",
        "# Example Calculation\n",
        "\n",
        "From the code’s test case:  \n",
        "**Query:** `[\"absolutely\", \"my\"]`  \n",
        "\n",
        "Assume training data has:  \n",
        "\n",
        "- Total lies (`numLie`) = 5,000  \n",
        "- Total truths (`numNotLie`) = 6,188  \n",
        "- **absolutely** appears in 3,000 lies and 1,000 truths  \n",
        "- **my** appears in 2,500 lies and 4,000 truths  \n",
        "\n",
        "## Step 1: Priors  \n",
        "\n",
        "P(Lie) = 5000 / 11188 = 0.447\n",
        "\n",
        "P(Not Lie) = 1 - 0.447 = 0.553\n",
        "\n",
        "## Step 2: Likelihoods  \n",
        "\n",
        "P( absolutely | Lie ) = 3000 / 5000 = 0.6\n",
        "\n",
        "P( absolutely | Not Lie) = 1000/6188 = 0.162\n",
        "\n",
        "P( my | Lie) = 2500 / 5000 = 0.5\n",
        "\n",
        "P( my | Not Lie) = 4000 / 6188 = 0.646\n",
        "\n",
        "\n",
        "## Step 3: Joint Probabilities  \n",
        "\n",
        "P(Query | Lie) = 0.6 * 0.5 = 0.3\n",
        "\n",
        "P(Query | Not Lie) = 0.162 * 0.646 = 0.105\n",
        "\n",
        "\n",
        "## Step 4: Posterior  \n",
        "\n",
        "P(Lie | Query) = 0.3 * 0.447 / (0.3* 0.447 + 0.105 * 0.553) = 0.698\n",
        "\n"
      ],
      "metadata": {
        "id": "T488gh_JTAv8"
      },
      "id": "T488gh_JTAv8"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "33518b4e-4b88-4c69-bee7-43e701386f20",
      "metadata": {
        "id": "33518b4e-4b88-4c69-bee7-43e701386f20"
      },
      "outputs": [],
      "source": [
        "def calculate_lie_probability(training_data, query):\n",
        "    \"\"\"\n",
        "    Calculate the probability of an input statement being spam.\n",
        "\n",
        "    Args:\n",
        "        training_data (list of tuples): Each tuple contains a list of words and a boolean indicating\n",
        "                                        if the list is lie (True) or not lie (False).\n",
        "        query (list of str): Words in the input statement to evaluate.\n",
        "\n",
        "    Returns:\n",
        "        float: Probability that the input statement is lie.\n",
        "    \"\"\"\n",
        "    P_lie_given_query = 1.0\n",
        "\n",
        "    # checks for at lest one valid word exist in the input statement\n",
        "    # and keep only the valid words\n",
        "    valid = False\n",
        "    valid_query = []\n",
        "    for i in query:\n",
        "        for words, isLie in training_data:\n",
        "            if i in words:\n",
        "                valid = True\n",
        "                valid_query.append(i)\n",
        "                break\n",
        "    if not valid:\n",
        "        return -1\n",
        "    query = valid_query\n",
        "\n",
        "    # calculate P(Wi|Lie) for all words within W*, along with P(Lie)\n",
        "    PLie = 0\n",
        "    numLie = 0\n",
        "    P_Wi_given_lie_list = []\n",
        "    P_Wi_given_not_lie_list = []\n",
        "    for i in query:\n",
        "        numLie = 0\n",
        "        numWgivenLie = 0\n",
        "        numNotLie = 0\n",
        "        numWgivenNotLie = 0\n",
        "        for words, isLie in training_data:\n",
        "            if isLie:\n",
        "                numLie += 1\n",
        "                if i in words:\n",
        "                    numWgivenLie += 1\n",
        "            else:\n",
        "                numNotLie += 1\n",
        "                if i in words:\n",
        "                    numWgivenNotLie += 1\n",
        "        PLie = numLie / len(training_data)\n",
        "        PNotLie = 1 - PLie\n",
        "        # Store P(Wi|Lie)\n",
        "        P_Wi_given_lie_list.append(numWgivenLie/numLie)\n",
        "        # Store P(Wi|notLie)\n",
        "        P_Wi_given_not_lie_list.append(numWgivenNotLie/numNotLie)\n",
        "\n",
        "    PLie = numLie / len(training_data)\n",
        "    PNotLie = 1 - PLie\n",
        "\n",
        "    # Calculate P(W*|Lie)\n",
        "    P_W_given_Lie = 1\n",
        "    for i in P_Wi_given_lie_list:\n",
        "        P_W_given_Lie *= i\n",
        "\n",
        "    # Calculate P(W*|notLie)\n",
        "    P_W_given_not_Lie = 1\n",
        "    for i in P_Wi_given_not_lie_list:\n",
        "        P_W_given_not_Lie *= i\n",
        "\n",
        "    if P_W_given_Lie == 0 and P_W_given_not_Lie == 0:\n",
        "      return -1\n",
        "\n",
        "    # Calculate P_lie_given_query\n",
        "    P_lie_given_query = P_W_given_Lie * PLie / (P_W_given_Lie * PLie + P_W_given_not_Lie * PNotLie)\n",
        "\n",
        "    return P_lie_given_query"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Handle Unknown word\n",
        "  Words not present in the training data are removed from the query. If all words are invalid, the model returns -1 (unknown)\n",
        "#### Motivation:\n",
        "\n",
        "- Simplifies the problem by ignoring words that the model hasn’t learned to associate with lies/truths.\n"
      ],
      "metadata": {
        "id": "hFenaxGeOqSJ"
      },
      "id": "hFenaxGeOqSJ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##OOV Problem & Short Statements\n",
        "###Current Handling:\n",
        "\n",
        "- Delete OOV words. For short statements, this risks leaving only common propositional words (e.g., “the”, “is”), which are uninformative.\n",
        "\n",
        "- Example: Query [\"wn\", \"m\"] returns -100% due to no valid words.\n",
        "\n",
        "### There might have Better Approaches:\n",
        "\n",
        "- Minimum Word Threshold: Require a minimum number of valid words to make predictions.\n",
        "\n",
        "- New Token: Set a new token <UNK>, which represents all the words that are invalid."
      ],
      "metadata": {
        "id": "vrOJU4a8RQqu"
      },
      "id": "vrOJU4a8RQqu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rare Words & Generalization\n",
        "### Problem:\n",
        "\n",
        "Words appearing very few times in training data (e.g., 1–2 occurrences) lead to noisy estimates of\n",
        "P( W<sub>i</sub> ∣ Class )\n",
        "\n",
        "\n",
        "- Example: If “absolutely” appears once in lies and never in truths,\n",
        "P( absolutely ∣ Lie )=1, which is unreliable.\n",
        "\n",
        "### Possible Solution\n",
        "- Word Embeddings:\n",
        "\n",
        "  Replace bag-of-words with embeddings (e.g., Word2Vec) to capture semantic similarity.\n",
        "\n",
        "  Advantage: Generalizes to synonyms (e.g., “money” ↔ “cash”).\n"
      ],
      "metadata": {
        "id": "FLRcf1NoSCax"
      },
      "id": "FLRcf1NoSCax"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "b07c16d0-ce99-4bea-93ad-4311a9cb1f1e",
      "metadata": {
        "id": "b07c16d0-ce99-4bea-93ad-4311a9cb1f1e"
      },
      "outputs": [],
      "source": [
        "def determine_lie(training_data,query):\n",
        "    result = calculate_lie_probability(training_data, query)\n",
        "    if result >= 0.5:\n",
        "        print (\"Lie!\")\n",
        "    elif result >= 0 and result < 0.5:\n",
        "        print (\"Truth\")\n",
        "    else:\n",
        "        print (\"Hmm, I have never seen anything like this before. I may need to upgrade my training data in the future. For now, try another sentence.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def userInput():\n",
        "    uInput = input(\"Please enter a sentence: \")\n",
        "    arr = uInput.split()\n",
        "    return arr"
      ],
      "metadata": {
        "id": "7fG1QdaqY3GI"
      },
      "id": "7fG1QdaqY3GI",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test user input function\n",
        "#I will absolutely sign this contract for money\n",
        "query = userInput()\n",
        "while( not query == [\"stop\"]):\n",
        "    result = determine_lie(training_data, query)\n",
        "    query = userInput()"
      ],
      "metadata": {
        "id": "oXuovjDGXcx4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "1f5dedf3-c3a8-4d55-a897-564aba5001ae"
      },
      "id": "oXuovjDGXcx4",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-afcd561fc53c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Test user input function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#I will absolutely sign this contract for money\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"stop\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetermine_lie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-344d15c6de5f>\u001b[0m in \u001b[0;36muserInput\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0muserInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0muInput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Please enter a sentence: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muInput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a0010db-d2a0-4217-8bca-bdcfaf95e895",
      "metadata": {
        "id": "0a0010db-d2a0-4217-8bca-bdcfaf95e895"
      },
      "source": [
        "#### the cells below is only for testing the determine_lie function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Test with validation set\n",
        "total_count = len(validation_data)\n",
        "correct_count = 0\n",
        "for sentence, veracity in validation_data:\n",
        "  prob = calculate_lie_probability(training_data, sentence)\n",
        "  if prob >= 0.5:\n",
        "    if veracity:\n",
        "      correct_count += 1\n",
        "  elif prob >= 0 and prob < 0.5:\n",
        "    if not veracity:\n",
        "      correct_count += 1\n",
        "  else:\n",
        "    total_count -= 1\n",
        "accuracy = correct_count / total_count\n",
        "print(f\"The accuracy obtained from the validation set is {accuracy * 100:.2f}% .\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0deJn4xQarMJ",
        "outputId": "6ef1c512-c748-4f10-9a32-e32a33fde5d7"
      },
      "id": "0deJn4xQarMJ",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy obtained from the validation set is 58.43% .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "7fdc0d24-303d-4e54-85cf-04847aa93ac9",
      "metadata": {
        "id": "7fdc0d24-303d-4e54-85cf-04847aa93ac9",
        "outputId": "aca318dd-32c5-45a0-d26e-39084c703fb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This sentence is -100.00% likely to be a lie.\n",
            "Hmm, I have never seen anything like this before. I may need to upgrade my training data in the future. For now, try another sentence.\n",
            "This sentence is 59.86% likely to be a lie.\n",
            "Lie!\n",
            "This sentence is 68.17% likely to be a lie.\n",
            "Lie!\n",
            "This sentence is 61.46% likely to be a lie.\n",
            "Lie!\n",
            "This sentence is 61.46% likely to be a lie.\n",
            "Lie!\n",
            "This sentence is 60.00% likely to be a lie.\n",
            "Lie!\n",
            "This sentence is 60.87% likely to be a lie.\n",
            "Lie!\n",
            "This sentence is 74.68% likely to be a lie.\n",
            "Lie!\n"
          ]
        }
      ],
      "source": [
        "#  Testing with or without own dataset\n",
        "#  training_data = [(['must', 'absolutely'], True),\n",
        "#  (['must', 'work', 'promise', 'absolutely'], False),\n",
        "#  (['money', 'contract'], True),\n",
        "#  (['money', 'work'], False),\n",
        "#  (['must'], True),\n",
        "#  (['must', 'money', 'contract'], True),\n",
        "#  (['must', 'money', 'contract', 'work'], True),\n",
        "#  (['project', 'absolutely'], False),\n",
        "#  (['work', 'absolutely'], False),\n",
        "#  (['work', 'promise'], False)]\n",
        "\n",
        "query = [\"wn\", \"m\"]\n",
        "prob = calculate_lie_probability(training_data, query)\n",
        "print(f\"This sentence is {prob * 100:.2f}% likely to be a lie.\")\n",
        "result = determine_lie(training_data, query)\n",
        "\n",
        "query = [\"absolutely\", \"my\"]\n",
        "prob = calculate_lie_probability(training_data, query)\n",
        "print(f\"This sentence is {prob * 100:.2f}% likely to be a lie.\")\n",
        "result = determine_lie(training_data, query)\n",
        "\n",
        "query = ['absolutely', 'work']\n",
        "prob = calculate_lie_probability(training_data, query)\n",
        "print(f\"This sentence is {prob * 100:.2f}% likely to be a lie.\")\n",
        "result = determine_lie(training_data, query)\n",
        "\n",
        "query = ['must', 'money']\n",
        "prob = calculate_lie_probability(training_data, query)\n",
        "print(f\"This sentence is {prob * 100:.2f}% likely to be a lie.\")\n",
        "result = determine_lie(training_data, query)\n",
        "\n",
        "query = ['money', 'must']\n",
        "prob = calculate_lie_probability(training_data, query)\n",
        "print(f\"This sentence is {prob * 100:.2f}% likely to be a lie.\")\n",
        "result = determine_lie(training_data, query)\n",
        "\n",
        "query = [\"absolutely\"]\n",
        "prob = calculate_lie_probability(training_data, query)\n",
        "print(f\"This sentence is {prob * 100:.2f}% likely to be a lie.\")\n",
        "result = determine_lie(training_data, query)\n",
        "\n",
        "query = [\"contract\", \"money\", \"absolutely\"]\n",
        "prob = calculate_lie_probability(training_data, query)\n",
        "print(f\"This sentence is {prob * 100:.2f}% likely to be a lie.\")\n",
        "result = determine_lie(training_data, query)\n",
        "\n",
        "query = [\"I\", \"will\", \"absolutely\",\"sign\", \"this\", \"contract\",\"for\", \"money\"]\n",
        "prob = calculate_lie_probability(training_data, query)\n",
        "print(f\"This sentence is {prob * 100:.2f}% likely to be a lie.\")\n",
        "result = determine_lie(training_data, query)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Benchmarking & Performance Analysis\n",
        "\n",
        "By validation set, the accuracy is 58.43%\n",
        "\n",
        "###Compare against baselines:\n",
        "\n",
        "- Random Guessing: Accuracy ≈ 50% (balanced data).\n",
        "\n",
        "- Always Predict Lie: Accuracy = % of lies in test data.\n",
        "\n",
        "###Model does a little bit better than baseline Baselines"
      ],
      "metadata": {
        "id": "lx9-HYOeXFo1"
      },
      "id": "lx9-HYOeXFo1"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CJyC21tbijeP"
      },
      "id": "CJyC21tbijeP",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}